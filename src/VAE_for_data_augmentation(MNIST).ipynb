{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoders for MNIST data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T20:24:09.297330Z",
     "start_time": "2019-01-04T20:24:09.284564Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T20:24:09.308492Z",
     "start_time": "2019-01-04T20:24:09.303379Z"
    }
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T20:24:09.326489Z",
     "start_time": "2019-01-04T20:24:09.311101Z"
    }
   },
   "outputs": [],
   "source": [
    "CUDA = True\n",
    "SEED = 1\n",
    "BATCH_SIZE = 128\n",
    "LOG_INTERVAL = 10\n",
    "EPOCHS = 25\n",
    "\n",
    "ZDIMS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T20:24:09.472251Z",
     "start_time": "2019-01-04T20:24:09.328884Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataLoader instances will load tensors directly into GPU memory\n",
    "data_loader_args = {'num_workers': 4, 'pin_memory': True} if CUDA else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **data_loader_args)\n",
    "\n",
    "# Same for test data\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **data_loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T20:24:09.483759Z",
     "start_time": "2019-01-04T20:24:09.478800Z"
    }
   },
   "outputs": [],
   "source": [
    "# for img in train_loader:\n",
    "#     print(img[1])\n",
    "    \n",
    "# #     plt.imshow(img, cmap='gray')\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T20:24:09.508112Z",
     "start_time": "2019-01-04T20:24:09.487924Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # ENCODER\n",
    "        # 28 x 28 pixels = 784 input pixels, 400 outputs\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        # rectified linear unit layer from 400 to 400\n",
    "        # max(0, x)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc21 = nn.Linear(400, ZDIMS)  # mu layer\n",
    "        self.fc22 = nn.Linear(400, ZDIMS)  # logvariance layer\n",
    "        # this last layer bottlenecks through ZDIMS connections\n",
    "\n",
    "        # DECODER\n",
    "        # from bottleneck to hidden 400\n",
    "        self.fc3 = nn.Linear(ZDIMS, 400)\n",
    "        # from hidden 400 to 784 outputs\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x: Variable) -> (Variable, Variable):\n",
    "        \"\"\"Input vector x -> fully connected 1 -> ReLU -> (fully connected\n",
    "        21, fully connected 22)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : [128, 784] matrix; 128 digits of 28x28 pixels each\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        (mu, logvar) : ZDIMS mean units one for each latent dimension, ZDIMS\n",
    "            variance units one for each latent dimension\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # h1 is [128, 400]\n",
    "        h1 = self.relu(self.fc1(x))  # type: Variable\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu: Variable, logvar: Variable) -> Variable:\n",
    "        \"\"\"THE REPARAMETERIZATION IDEA:\n",
    "\n",
    "        For each training sample (we get 128 batched at a time)\n",
    "\n",
    "        - take the current learned mu, stddev for each of the ZDIMS\n",
    "          dimensions and draw a random sample from that distribution\n",
    "        - the whole network is trained so that these randomly drawn\n",
    "          samples decode to output that looks like the input\n",
    "        - which will mean that the std, mu will be learned\n",
    "          *distributions* that correctly encode the inputs\n",
    "        - due to the additional KLD term (see loss_function() below)\n",
    "          the distribution will tend to unit Gaussians\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mu : [128, ZDIMS] mean matrix\n",
    "        logvar : [128, ZDIMS] variance matrix\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        During training random sample from the learned ZDIMS-dimensional\n",
    "        normal distribution; during inference its mean.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if self.training:\n",
    "            # multiply log variance with 0.5, then in-place exponent\n",
    "            # yielding the standard deviation\n",
    "            std = logvar.mul(0.5).exp_()  # type: Variable\n",
    "            # - std.data is the [128,ZDIMS] tensor that is wrapped by std\n",
    "            # - so eps is [128,ZDIMS] with all elements drawn from a mean 0\n",
    "            #   and stddev 1 normal distribution that is 128 samples\n",
    "            #   of random ZDIMS-float vectors\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            # - sample from a normal distribution with standard\n",
    "            #   deviation = std and mean = mu by multiplying mean 0\n",
    "            #   stddev 1 sample with desired std and mu, see\n",
    "            #   https://stats.stackexchange.com/a/16338\n",
    "            # - so we have 128 sets (the batch) of random ZDIMS-float\n",
    "            #   vectors sampled from normal distribution with learned\n",
    "            #   std and mu for the current input\n",
    "            return eps.mul(std).add_(mu)\n",
    "\n",
    "        else:\n",
    "            # During inference, we simply spit out the mean of the\n",
    "            # learned distribution for the current input.  We could\n",
    "            # use a random sample from the distribution, but mu of\n",
    "            # course has the highest probability.\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z: Variable) -> Variable:\n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        return self.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x: Variable) -> (Variable, Variable, Variable):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "    def transform(self, x, eps=0.1):\n",
    "        mean, var = self.encode(x)\n",
    "        noise = Variable(1. + torch.randn(x.size(0), ZDIMS) * eps).cuda()\n",
    "        z = self.reparameterize(mean*noise, var*noise)\n",
    "        out = self.decode(z)\n",
    "    \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T20:24:09.519506Z",
     "start_time": "2019-01-04T20:24:09.509660Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar) -> Variable:\n",
    "    # how well do input x and output recon_x agree?\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784))\n",
    "\n",
    "    # KLD is Kullbackâ€“Leibler divergence -- how much does one learned\n",
    "    # distribution deviate from another, in this specific case the\n",
    "    # learned distribution from the unit Gaussian\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # - D_{KL} = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    # note the negative D_{KL} in appendix B of the paper\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    # Normalise by same number of elements as in reconstruction\n",
    "    KLD /= BATCH_SIZE * 784\n",
    "\n",
    "    # BCE tries to make our reconstruction as accurate as possible\n",
    "    # KLD tries to push the distributions as close as possible to unit Gaussian\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T20:24:09.527522Z",
     "start_time": "2019-01-04T20:24:09.521173Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    # toggle model to train mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    # in the case of MNIST, len(train_loader.dataset) is 60000\n",
    "    # each `data` is of BATCH_SIZE samples and has shape [128, 1, 28, 28]\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # push whole batch of data through VAE.forward() to get recon_loss\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        # calculate scalar loss\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        # calculate the gradient of the loss w.r.t. the graph leaves\n",
    "        # i.e. input variables -- by the power of pytorch!\n",
    "        loss.backward()\n",
    "        \n",
    "        train_loss += loss.data.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T20:24:38.951217Z",
     "start_time": "2019-01-04T20:24:38.945010Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    # toggle model to test / inference mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    # each data is of BATCH_SIZE (default 128) samples\n",
    "    for i, (data, _) in enumerate(test_loader):\n",
    "        if CUDA:\n",
    "            # make sure this lives on the GPU\n",
    "            data = data.cuda()\n",
    "\n",
    "        # we're only going to infer, so no autograd at all required: volatile=True\n",
    "        data = Variable(data, volatile=True)\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        test_loss += loss_function(recon_batch, data, mu, logvar).data.item()\n",
    "        if i == 0:\n",
    "          n = min(data.size(0), 8)\n",
    "          # for the first 128 batch of the epoch, show the first 8 input digits\n",
    "          # with right below them the reconstructed output digits\n",
    "          comparison = torch.cat([data[:n],\n",
    "                                  recon_batch.view(BATCH_SIZE, 1, 28, 28)[:n]])\n",
    "          save_image(comparison.data.cpu(),\n",
    "                     'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T20:24:38.964979Z",
     "start_time": "2019-01-04T20:24:38.953610Z"
    }
   },
   "outputs": [],
   "source": [
    "model = VAE()\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "    \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T20:25:46.197419Z",
     "start_time": "2019-01-04T20:24:38.967128Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.005443\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.003072\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.002375\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.002216\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.002191\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.002149\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.002035\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.002089\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.001917\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.001899\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.001814\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.001777\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.001701\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.001713\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.001658\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.001686\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.001568\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.001574\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.001583\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.001545\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.001546\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.001418\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.001529\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.001486\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.001425\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.001423\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.001384\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.001400\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.001395\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.001439\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.001381\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.001409\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.001361\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.001362\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.001379\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.001300\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.001399\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.001290\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.001281\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.001292\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.001354\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.001319\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.001316\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.001278\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.001316\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.001244\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.001274\n",
      "====> Epoch: 1 Average loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:13: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0012\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.001310\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.001225\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.001229\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.001286\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.001245\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.001252\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.001260\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.001257\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.001280\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.001278\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.001297\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.001227\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.001197\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.001260\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.001253\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.001201\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.001171\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.001169\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.001169\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.001279\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.001206\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.001239\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.001271\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.001192\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.001184\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.001216\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.001176\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.001135\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.001179\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.001210\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.001258\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.001143\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.001158\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.001176\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.001183\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.001174\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.001158\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.001161\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.001160\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.001179\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.001152\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.001191\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.001190\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.001170\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.001144\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.001148\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.001133\n",
      "====> Epoch: 2 Average loss: 0.0012\n",
      "====> Test set loss: 0.0011\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.001191\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.001120\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.001174\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.001111\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.001105\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.001157\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.001172\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.001201\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.001159\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.001121\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.001154\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.001110\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.001144\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.001139\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.001106\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.001124\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.001163\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.001141\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.001143\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.001135\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.001138\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.001158\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.001117\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.001146\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.001182\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.001149\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.001172\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.001127\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.001102\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.001158\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.001194\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.001140\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.001144\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.001112\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.001112\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.001140\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.001129\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.001117\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.001144\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.001109\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.001135\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.001134\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.001121\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.001119\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.001110\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.001116\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.001103\n",
      "====> Epoch: 3 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.001152\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.001113\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.001103\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.001079\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.001081\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.001142\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.001066\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.001099\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.001152\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.001109\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.001115\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.001082\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.001125\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.001104\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.001129\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.001116\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.001079\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.001187\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.001059\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.001091\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.001136\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.001096\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.001120\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.001087\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.001127\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.001098\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.001087\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.001063\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.001099\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.001082\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.001128\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.001119\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.001128\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.001140\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.001070\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.001118\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.001126\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.001100\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.001066\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.001093\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.001138\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.001135\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.001124\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.001102\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.001139\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.001145\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.001108\n",
      "====> Epoch: 4 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.001137\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.001077\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.001098\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.001098\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.001096\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.001065\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.001083\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.001122\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.001077\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.001095\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.001108\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.001076\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.001096\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.001098\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.001082\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.001129\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.001108\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.001122\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.001080\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.001111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.001090\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.001093\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.001074\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.001121\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.001082\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.001140\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.001074\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.001116\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.001105\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.001091\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.001090\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.001059\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.001105\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.001117\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.001053\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.001133\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.001094\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.001106\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.001149\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.001099\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.001102\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.001051\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.001121\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.001097\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.001085\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.001099\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.001122\n",
      "====> Epoch: 5 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.001118\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.001082\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.001080\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.001065\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.001071\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.001068\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.001102\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.001125\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.001084\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.001125\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.001071\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.001062\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.001049\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.001084\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.001104\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.001088\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.001116\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.001073\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.001058\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.001069\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.001086\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.001068\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.001097\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.001057\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.001100\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.001072\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.001104\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.001083\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.001108\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.001068\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.001082\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.001065\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.001096\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.001122\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.001102\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.001105\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.001060\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.001066\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.001057\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.001116\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.001057\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.001053\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.001111\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.001107\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.001101\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.001078\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.001097\n",
      "====> Epoch: 6 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.001066\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.001061\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.001066\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.001083\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.001082\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.001073\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.001054\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.001092\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.001085\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.001079\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.001100\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.001090\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.001103\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.001075\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.001047\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.001104\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.001042\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.001091\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.001100\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.001052\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.001074\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.001091\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.001035\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.001056\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.001075\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.001040\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.001085\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.001042\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.001036\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.001071\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.001056\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.001073\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.001058\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.001036\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.001114\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.001024\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.001060\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.001119\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.001102\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.001088\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.001116\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.001061\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.001072\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.001047\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.001050\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.001016\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.001114\n",
      "====> Epoch: 7 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.001097\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.001124\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.001102\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.001048\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.001052\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.001105\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.001068\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.001062\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.001052\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.001083\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.001090\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.001077\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.001060\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.001101\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.001059\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.001024\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.001047\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.001070\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.001034\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.001098\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.001074\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.001024\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.001068\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.001082\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.001058\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.001049\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.001058\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.001031\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.001108\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.001059\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.001088\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.001013\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.001090\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.001043\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.001046\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.001041\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.001079\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.001095\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.001048\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.001081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.001043\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.001060\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.001086\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.001055\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.001059\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.001020\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.001062\n",
      "====> Epoch: 8 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.001066\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.001098\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.001053\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.001027\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.001068\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.001087\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.001018\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.001069\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.001023\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.001065\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.001093\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.001078\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.001042\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.001072\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.001065\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.001064\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.001071\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.001049\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.001075\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.001047\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.001087\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.001027\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.000997\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.001118\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.001063\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.001087\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.001038\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.001067\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.001054\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.001058\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.001033\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.001051\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.001083\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.001013\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.001052\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.001064\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.001016\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.001075\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.001058\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.001077\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.001038\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.001098\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.001065\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.001046\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.001087\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.001077\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.001070\n",
      "====> Epoch: 9 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.001057\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.001075\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.001069\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.001015\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.001063\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.001057\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.001075\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.001046\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.001081\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.001048\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.001063\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.001055\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.001031\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.001012\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.001054\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.001049\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.001047\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.001066\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.001075\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.001093\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.001040\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.001026\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.001049\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.001068\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.001066\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.001037\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.001080\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.001085\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.001056\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.001036\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.001105\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.001072\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.001050\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.001043\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.001103\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.001049\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.001086\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.001054\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.001055\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.001101\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.001040\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.001021\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.001062\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.001045\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.001056\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.001039\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.001037\n",
      "====> Epoch: 10 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.001047\n",
      "Train Epoch: 11 [1280/60000 (2%)]\tLoss: 0.001029\n",
      "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 0.001069\n",
      "Train Epoch: 11 [3840/60000 (6%)]\tLoss: 0.001044\n",
      "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 0.001061\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.001059\n",
      "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 0.001098\n",
      "Train Epoch: 11 [8960/60000 (15%)]\tLoss: 0.001067\n",
      "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 0.001043\n",
      "Train Epoch: 11 [11520/60000 (19%)]\tLoss: 0.001038\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.001108\n",
      "Train Epoch: 11 [14080/60000 (23%)]\tLoss: 0.001034\n",
      "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 0.001053\n",
      "Train Epoch: 11 [16640/60000 (28%)]\tLoss: 0.001057\n",
      "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 0.001072\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.001072\n",
      "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 0.001035\n",
      "Train Epoch: 11 [21760/60000 (36%)]\tLoss: 0.001085\n",
      "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 0.001057\n",
      "Train Epoch: 11 [24320/60000 (41%)]\tLoss: 0.001052\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.001060\n",
      "Train Epoch: 11 [26880/60000 (45%)]\tLoss: 0.001072\n",
      "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 0.001080\n",
      "Train Epoch: 11 [29440/60000 (49%)]\tLoss: 0.001043\n",
      "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 0.001041\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.001049\n",
      "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 0.001000\n",
      "Train Epoch: 11 [34560/60000 (58%)]\tLoss: 0.001059\n",
      "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 0.001051\n",
      "Train Epoch: 11 [37120/60000 (62%)]\tLoss: 0.001059\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.001093\n",
      "Train Epoch: 11 [39680/60000 (66%)]\tLoss: 0.001060\n",
      "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 0.001076\n",
      "Train Epoch: 11 [42240/60000 (70%)]\tLoss: 0.001064\n",
      "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 0.001063\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.001050\n",
      "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 0.001054\n",
      "Train Epoch: 11 [47360/60000 (79%)]\tLoss: 0.001092\n",
      "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 0.001022\n",
      "Train Epoch: 11 [49920/60000 (83%)]\tLoss: 0.001062\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.001063\n",
      "Train Epoch: 11 [52480/60000 (87%)]\tLoss: 0.001052\n",
      "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 0.001038\n",
      "Train Epoch: 11 [55040/60000 (92%)]\tLoss: 0.001060\n",
      "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 0.001013\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.001027\n",
      "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 0.001041\n",
      "====> Epoch: 11 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.001017\n",
      "Train Epoch: 12 [1280/60000 (2%)]\tLoss: 0.001076\n",
      "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 0.001070\n",
      "Train Epoch: 12 [3840/60000 (6%)]\tLoss: 0.001050\n",
      "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 0.001077\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.001042\n",
      "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 0.001021\n",
      "Train Epoch: 12 [8960/60000 (15%)]\tLoss: 0.001005\n",
      "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 0.001033\n",
      "Train Epoch: 12 [11520/60000 (19%)]\tLoss: 0.001030\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.001051\n",
      "Train Epoch: 12 [14080/60000 (23%)]\tLoss: 0.001021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 0.001103\n",
      "Train Epoch: 12 [16640/60000 (28%)]\tLoss: 0.001075\n",
      "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 0.001060\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.001040\n",
      "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 0.001063\n",
      "Train Epoch: 12 [21760/60000 (36%)]\tLoss: 0.001092\n",
      "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 0.001014\n",
      "Train Epoch: 12 [24320/60000 (41%)]\tLoss: 0.001034\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.001078\n",
      "Train Epoch: 12 [26880/60000 (45%)]\tLoss: 0.001043\n",
      "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 0.001034\n",
      "Train Epoch: 12 [29440/60000 (49%)]\tLoss: 0.001067\n",
      "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 0.001021\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.001041\n",
      "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 0.001029\n",
      "Train Epoch: 12 [34560/60000 (58%)]\tLoss: 0.001098\n",
      "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 0.001025\n",
      "Train Epoch: 12 [37120/60000 (62%)]\tLoss: 0.001067\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.001084\n",
      "Train Epoch: 12 [39680/60000 (66%)]\tLoss: 0.001085\n",
      "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 0.001023\n",
      "Train Epoch: 12 [42240/60000 (70%)]\tLoss: 0.001048\n",
      "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 0.001017\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.001043\n",
      "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 0.001031\n",
      "Train Epoch: 12 [47360/60000 (79%)]\tLoss: 0.001000\n",
      "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 0.001026\n",
      "Train Epoch: 12 [49920/60000 (83%)]\tLoss: 0.001073\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.001040\n",
      "Train Epoch: 12 [52480/60000 (87%)]\tLoss: 0.001026\n",
      "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 0.001088\n",
      "Train Epoch: 12 [55040/60000 (92%)]\tLoss: 0.001064\n",
      "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 0.001062\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.001053\n",
      "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 0.001061\n",
      "====> Epoch: 12 Average loss: 0.0011\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.001044\n",
      "Train Epoch: 13 [1280/60000 (2%)]\tLoss: 0.001004\n",
      "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 0.001035\n",
      "Train Epoch: 13 [3840/60000 (6%)]\tLoss: 0.001038\n",
      "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 0.001008\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.001067\n",
      "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 0.001062\n",
      "Train Epoch: 13 [8960/60000 (15%)]\tLoss: 0.001058\n",
      "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 0.001055\n",
      "Train Epoch: 13 [11520/60000 (19%)]\tLoss: 0.001054\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.001026\n",
      "Train Epoch: 13 [14080/60000 (23%)]\tLoss: 0.001074\n",
      "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 0.001003\n",
      "Train Epoch: 13 [16640/60000 (28%)]\tLoss: 0.001053\n",
      "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 0.001056\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.001057\n",
      "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 0.001046\n",
      "Train Epoch: 13 [21760/60000 (36%)]\tLoss: 0.001078\n",
      "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 0.001039\n",
      "Train Epoch: 13 [24320/60000 (41%)]\tLoss: 0.001086\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.001047\n",
      "Train Epoch: 13 [26880/60000 (45%)]\tLoss: 0.001081\n",
      "Train Epoch: 13 [28160/60000 (47%)]\tLoss: 0.001024\n",
      "Train Epoch: 13 [29440/60000 (49%)]\tLoss: 0.001045\n",
      "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 0.001044\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.001036\n",
      "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 0.001074\n",
      "Train Epoch: 13 [34560/60000 (58%)]\tLoss: 0.001041\n",
      "Train Epoch: 13 [35840/60000 (60%)]\tLoss: 0.001079\n",
      "Train Epoch: 13 [37120/60000 (62%)]\tLoss: 0.001075\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.001079\n",
      "Train Epoch: 13 [39680/60000 (66%)]\tLoss: 0.001041\n",
      "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 0.001046\n",
      "Train Epoch: 13 [42240/60000 (70%)]\tLoss: 0.001010\n",
      "Train Epoch: 13 [43520/60000 (72%)]\tLoss: 0.001081\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.001033\n",
      "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 0.001022\n",
      "Train Epoch: 13 [47360/60000 (79%)]\tLoss: 0.001041\n",
      "Train Epoch: 13 [48640/60000 (81%)]\tLoss: 0.001055\n",
      "Train Epoch: 13 [49920/60000 (83%)]\tLoss: 0.001074\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.001005\n",
      "Train Epoch: 13 [52480/60000 (87%)]\tLoss: 0.001076\n",
      "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 0.001049\n",
      "Train Epoch: 13 [55040/60000 (92%)]\tLoss: 0.000964\n",
      "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 0.001069\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.001061\n",
      "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 0.001061\n",
      "====> Epoch: 13 Average loss: 0.0010\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.001073\n",
      "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.001033\n",
      "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.001090\n",
      "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.001034\n",
      "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.001067\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.001050\n",
      "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.001028\n",
      "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.001007\n",
      "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.001042\n",
      "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.001067\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.001088\n",
      "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.001053\n",
      "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.001080\n",
      "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.001033\n",
      "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.001049\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.001038\n",
      "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.001056\n",
      "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.001034\n",
      "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.001054\n",
      "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.001025\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.001047\n",
      "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.001076\n",
      "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.000996\n",
      "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.001056\n",
      "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.001048\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.001014\n",
      "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.001051\n",
      "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.001062\n",
      "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.001057\n",
      "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.001053\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.001065\n",
      "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.001020\n",
      "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.001057\n",
      "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.001050\n",
      "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.001023\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.001045\n",
      "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.000995\n",
      "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.001043\n",
      "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.001079\n",
      "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.001046\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.001050\n",
      "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.001033\n",
      "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.001023\n",
      "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.001047\n",
      "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.001068\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.001032\n",
      "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.001039\n",
      "====> Epoch: 14 Average loss: 0.0010\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.001055\n",
      "Train Epoch: 15 [1280/60000 (2%)]\tLoss: 0.001083\n",
      "Train Epoch: 15 [2560/60000 (4%)]\tLoss: 0.001027\n",
      "Train Epoch: 15 [3840/60000 (6%)]\tLoss: 0.001031\n",
      "Train Epoch: 15 [5120/60000 (9%)]\tLoss: 0.001037\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.001047\n",
      "Train Epoch: 15 [7680/60000 (13%)]\tLoss: 0.001055\n",
      "Train Epoch: 15 [8960/60000 (15%)]\tLoss: 0.001024\n",
      "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 0.001067\n",
      "Train Epoch: 15 [11520/60000 (19%)]\tLoss: 0.001014\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.001003\n",
      "Train Epoch: 15 [14080/60000 (23%)]\tLoss: 0.001023\n",
      "Train Epoch: 15 [15360/60000 (26%)]\tLoss: 0.001064\n",
      "Train Epoch: 15 [16640/60000 (28%)]\tLoss: 0.001048\n",
      "Train Epoch: 15 [17920/60000 (30%)]\tLoss: 0.001039\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.001003\n",
      "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 0.001086\n",
      "Train Epoch: 15 [21760/60000 (36%)]\tLoss: 0.001057\n",
      "Train Epoch: 15 [23040/60000 (38%)]\tLoss: 0.001070\n",
      "Train Epoch: 15 [24320/60000 (41%)]\tLoss: 0.001038\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.001039\n",
      "Train Epoch: 15 [26880/60000 (45%)]\tLoss: 0.001058\n",
      "Train Epoch: 15 [28160/60000 (47%)]\tLoss: 0.001004\n",
      "Train Epoch: 15 [29440/60000 (49%)]\tLoss: 0.001048\n",
      "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 0.001023\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.001038\n",
      "Train Epoch: 15 [33280/60000 (55%)]\tLoss: 0.001054\n",
      "Train Epoch: 15 [34560/60000 (58%)]\tLoss: 0.001003\n",
      "Train Epoch: 15 [35840/60000 (60%)]\tLoss: 0.001054\n",
      "Train Epoch: 15 [37120/60000 (62%)]\tLoss: 0.001051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.001057\n",
      "Train Epoch: 15 [39680/60000 (66%)]\tLoss: 0.001077\n",
      "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 0.001039\n",
      "Train Epoch: 15 [42240/60000 (70%)]\tLoss: 0.001047\n",
      "Train Epoch: 15 [43520/60000 (72%)]\tLoss: 0.001086\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.001059\n",
      "Train Epoch: 15 [46080/60000 (77%)]\tLoss: 0.001048\n",
      "Train Epoch: 15 [47360/60000 (79%)]\tLoss: 0.001023\n",
      "Train Epoch: 15 [48640/60000 (81%)]\tLoss: 0.001072\n",
      "Train Epoch: 15 [49920/60000 (83%)]\tLoss: 0.001031\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.001056\n",
      "Train Epoch: 15 [52480/60000 (87%)]\tLoss: 0.001022\n",
      "Train Epoch: 15 [53760/60000 (90%)]\tLoss: 0.001059\n",
      "Train Epoch: 15 [55040/60000 (92%)]\tLoss: 0.001028\n",
      "Train Epoch: 15 [56320/60000 (94%)]\tLoss: 0.001050\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.001070\n",
      "Train Epoch: 15 [58880/60000 (98%)]\tLoss: 0.001045\n",
      "====> Epoch: 15 Average loss: 0.0010\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.001015\n",
      "Train Epoch: 16 [1280/60000 (2%)]\tLoss: 0.001054\n",
      "Train Epoch: 16 [2560/60000 (4%)]\tLoss: 0.001024\n",
      "Train Epoch: 16 [3840/60000 (6%)]\tLoss: 0.001057\n",
      "Train Epoch: 16 [5120/60000 (9%)]\tLoss: 0.001011\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.001030\n",
      "Train Epoch: 16 [7680/60000 (13%)]\tLoss: 0.001022\n",
      "Train Epoch: 16 [8960/60000 (15%)]\tLoss: 0.001026\n",
      "Train Epoch: 16 [10240/60000 (17%)]\tLoss: 0.001066\n",
      "Train Epoch: 16 [11520/60000 (19%)]\tLoss: 0.001055\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.001011\n",
      "Train Epoch: 16 [14080/60000 (23%)]\tLoss: 0.001037\n",
      "Train Epoch: 16 [15360/60000 (26%)]\tLoss: 0.001074\n",
      "Train Epoch: 16 [16640/60000 (28%)]\tLoss: 0.001029\n",
      "Train Epoch: 16 [17920/60000 (30%)]\tLoss: 0.001053\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.001013\n",
      "Train Epoch: 16 [20480/60000 (34%)]\tLoss: 0.001063\n",
      "Train Epoch: 16 [21760/60000 (36%)]\tLoss: 0.001022\n",
      "Train Epoch: 16 [23040/60000 (38%)]\tLoss: 0.001027\n",
      "Train Epoch: 16 [24320/60000 (41%)]\tLoss: 0.001032\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.001010\n",
      "Train Epoch: 16 [26880/60000 (45%)]\tLoss: 0.001064\n",
      "Train Epoch: 16 [28160/60000 (47%)]\tLoss: 0.001056\n",
      "Train Epoch: 16 [29440/60000 (49%)]\tLoss: 0.001062\n",
      "Train Epoch: 16 [30720/60000 (51%)]\tLoss: 0.001055\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.001030\n",
      "Train Epoch: 16 [33280/60000 (55%)]\tLoss: 0.001008\n",
      "Train Epoch: 16 [34560/60000 (58%)]\tLoss: 0.001062\n",
      "Train Epoch: 16 [35840/60000 (60%)]\tLoss: 0.001002\n",
      "Train Epoch: 16 [37120/60000 (62%)]\tLoss: 0.001020\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.001023\n",
      "Train Epoch: 16 [39680/60000 (66%)]\tLoss: 0.001021\n",
      "Train Epoch: 16 [40960/60000 (68%)]\tLoss: 0.001048\n",
      "Train Epoch: 16 [42240/60000 (70%)]\tLoss: 0.001031\n",
      "Train Epoch: 16 [43520/60000 (72%)]\tLoss: 0.001025\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.001018\n",
      "Train Epoch: 16 [46080/60000 (77%)]\tLoss: 0.001051\n",
      "Train Epoch: 16 [47360/60000 (79%)]\tLoss: 0.001075\n",
      "Train Epoch: 16 [48640/60000 (81%)]\tLoss: 0.001038\n",
      "Train Epoch: 16 [49920/60000 (83%)]\tLoss: 0.000988\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.001078\n",
      "Train Epoch: 16 [52480/60000 (87%)]\tLoss: 0.001071\n",
      "Train Epoch: 16 [53760/60000 (90%)]\tLoss: 0.001088\n",
      "Train Epoch: 16 [55040/60000 (92%)]\tLoss: 0.001082\n",
      "Train Epoch: 16 [56320/60000 (94%)]\tLoss: 0.001089\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.001038\n",
      "Train Epoch: 16 [58880/60000 (98%)]\tLoss: 0.001018\n",
      "====> Epoch: 16 Average loss: 0.0010\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.001019\n",
      "Train Epoch: 17 [1280/60000 (2%)]\tLoss: 0.001042\n",
      "Train Epoch: 17 [2560/60000 (4%)]\tLoss: 0.001034\n",
      "Train Epoch: 17 [3840/60000 (6%)]\tLoss: 0.001010\n",
      "Train Epoch: 17 [5120/60000 (9%)]\tLoss: 0.001061\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.001066\n",
      "Train Epoch: 17 [7680/60000 (13%)]\tLoss: 0.001007\n",
      "Train Epoch: 17 [8960/60000 (15%)]\tLoss: 0.001050\n",
      "Train Epoch: 17 [10240/60000 (17%)]\tLoss: 0.001065\n",
      "Train Epoch: 17 [11520/60000 (19%)]\tLoss: 0.001040\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.001082\n",
      "Train Epoch: 17 [14080/60000 (23%)]\tLoss: 0.001021\n",
      "Train Epoch: 17 [15360/60000 (26%)]\tLoss: 0.001046\n",
      "Train Epoch: 17 [16640/60000 (28%)]\tLoss: 0.001044\n",
      "Train Epoch: 17 [17920/60000 (30%)]\tLoss: 0.001021\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.001040\n",
      "Train Epoch: 17 [20480/60000 (34%)]\tLoss: 0.001060\n",
      "Train Epoch: 17 [21760/60000 (36%)]\tLoss: 0.001047\n",
      "Train Epoch: 17 [23040/60000 (38%)]\tLoss: 0.001031\n",
      "Train Epoch: 17 [24320/60000 (41%)]\tLoss: 0.001102\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.001029\n",
      "Train Epoch: 17 [26880/60000 (45%)]\tLoss: 0.001071\n",
      "Train Epoch: 17 [28160/60000 (47%)]\tLoss: 0.001042\n",
      "Train Epoch: 17 [29440/60000 (49%)]\tLoss: 0.001079\n",
      "Train Epoch: 17 [30720/60000 (51%)]\tLoss: 0.001045\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.001072\n",
      "Train Epoch: 17 [33280/60000 (55%)]\tLoss: 0.001019\n",
      "Train Epoch: 17 [34560/60000 (58%)]\tLoss: 0.001037\n",
      "Train Epoch: 17 [35840/60000 (60%)]\tLoss: 0.001028\n",
      "Train Epoch: 17 [37120/60000 (62%)]\tLoss: 0.001030\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.001039\n",
      "Train Epoch: 17 [39680/60000 (66%)]\tLoss: 0.001028\n",
      "Train Epoch: 17 [40960/60000 (68%)]\tLoss: 0.001036\n",
      "Train Epoch: 17 [42240/60000 (70%)]\tLoss: 0.001075\n",
      "Train Epoch: 17 [43520/60000 (72%)]\tLoss: 0.001026\n",
      "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 0.001061\n",
      "Train Epoch: 17 [46080/60000 (77%)]\tLoss: 0.001022\n",
      "Train Epoch: 17 [47360/60000 (79%)]\tLoss: 0.000997\n",
      "Train Epoch: 17 [48640/60000 (81%)]\tLoss: 0.001040\n",
      "Train Epoch: 17 [49920/60000 (83%)]\tLoss: 0.001050\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.001025\n",
      "Train Epoch: 17 [52480/60000 (87%)]\tLoss: 0.001047\n",
      "Train Epoch: 17 [53760/60000 (90%)]\tLoss: 0.001012\n",
      "Train Epoch: 17 [55040/60000 (92%)]\tLoss: 0.001078\n",
      "Train Epoch: 17 [56320/60000 (94%)]\tLoss: 0.001063\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.001036\n",
      "Train Epoch: 17 [58880/60000 (98%)]\tLoss: 0.001011\n",
      "====> Epoch: 17 Average loss: 0.0010\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.001014\n",
      "Train Epoch: 18 [1280/60000 (2%)]\tLoss: 0.001041\n",
      "Train Epoch: 18 [2560/60000 (4%)]\tLoss: 0.001028\n",
      "Train Epoch: 18 [3840/60000 (6%)]\tLoss: 0.001058\n",
      "Train Epoch: 18 [5120/60000 (9%)]\tLoss: 0.001013\n",
      "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 0.001016\n",
      "Train Epoch: 18 [7680/60000 (13%)]\tLoss: 0.001067\n",
      "Train Epoch: 18 [8960/60000 (15%)]\tLoss: 0.001017\n",
      "Train Epoch: 18 [10240/60000 (17%)]\tLoss: 0.001031\n",
      "Train Epoch: 18 [11520/60000 (19%)]\tLoss: 0.001036\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.001052\n",
      "Train Epoch: 18 [14080/60000 (23%)]\tLoss: 0.000983\n",
      "Train Epoch: 18 [15360/60000 (26%)]\tLoss: 0.001082\n",
      "Train Epoch: 18 [16640/60000 (28%)]\tLoss: 0.001065\n",
      "Train Epoch: 18 [17920/60000 (30%)]\tLoss: 0.001025\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.001047\n",
      "Train Epoch: 18 [20480/60000 (34%)]\tLoss: 0.001070\n",
      "Train Epoch: 18 [21760/60000 (36%)]\tLoss: 0.001065\n",
      "Train Epoch: 18 [23040/60000 (38%)]\tLoss: 0.001065\n",
      "Train Epoch: 18 [24320/60000 (41%)]\tLoss: 0.001026\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.001048\n",
      "Train Epoch: 18 [26880/60000 (45%)]\tLoss: 0.001054\n",
      "Train Epoch: 18 [28160/60000 (47%)]\tLoss: 0.000998\n",
      "Train Epoch: 18 [29440/60000 (49%)]\tLoss: 0.001027\n",
      "Train Epoch: 18 [30720/60000 (51%)]\tLoss: 0.001024\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.001046\n",
      "Train Epoch: 18 [33280/60000 (55%)]\tLoss: 0.001031\n",
      "Train Epoch: 18 [34560/60000 (58%)]\tLoss: 0.001037\n",
      "Train Epoch: 18 [35840/60000 (60%)]\tLoss: 0.001071\n",
      "Train Epoch: 18 [37120/60000 (62%)]\tLoss: 0.001009\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.001040\n",
      "Train Epoch: 18 [39680/60000 (66%)]\tLoss: 0.001020\n",
      "Train Epoch: 18 [40960/60000 (68%)]\tLoss: 0.001050\n",
      "Train Epoch: 18 [42240/60000 (70%)]\tLoss: 0.001049\n",
      "Train Epoch: 18 [43520/60000 (72%)]\tLoss: 0.001050\n",
      "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 0.001015\n",
      "Train Epoch: 18 [46080/60000 (77%)]\tLoss: 0.000996\n",
      "Train Epoch: 18 [47360/60000 (79%)]\tLoss: 0.001026\n",
      "Train Epoch: 18 [48640/60000 (81%)]\tLoss: 0.001021\n",
      "Train Epoch: 18 [49920/60000 (83%)]\tLoss: 0.001061\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.001049\n",
      "Train Epoch: 18 [52480/60000 (87%)]\tLoss: 0.001058\n",
      "Train Epoch: 18 [53760/60000 (90%)]\tLoss: 0.001035\n",
      "Train Epoch: 18 [55040/60000 (92%)]\tLoss: 0.001010\n",
      "Train Epoch: 18 [56320/60000 (94%)]\tLoss: 0.001042\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.001070\n",
      "Train Epoch: 18 [58880/60000 (98%)]\tLoss: 0.001034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 18 Average loss: 0.0010\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.001045\n",
      "Train Epoch: 19 [1280/60000 (2%)]\tLoss: 0.001030\n",
      "Train Epoch: 19 [2560/60000 (4%)]\tLoss: 0.001056\n",
      "Train Epoch: 19 [3840/60000 (6%)]\tLoss: 0.001056\n",
      "Train Epoch: 19 [5120/60000 (9%)]\tLoss: 0.001065\n",
      "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 0.001031\n",
      "Train Epoch: 19 [7680/60000 (13%)]\tLoss: 0.001026\n",
      "Train Epoch: 19 [8960/60000 (15%)]\tLoss: 0.001060\n",
      "Train Epoch: 19 [10240/60000 (17%)]\tLoss: 0.001042\n",
      "Train Epoch: 19 [11520/60000 (19%)]\tLoss: 0.001072\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.001060\n",
      "Train Epoch: 19 [14080/60000 (23%)]\tLoss: 0.001046\n",
      "Train Epoch: 19 [15360/60000 (26%)]\tLoss: 0.001006\n",
      "Train Epoch: 19 [16640/60000 (28%)]\tLoss: 0.001048\n",
      "Train Epoch: 19 [17920/60000 (30%)]\tLoss: 0.001029\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.001046\n",
      "Train Epoch: 19 [20480/60000 (34%)]\tLoss: 0.001027\n",
      "Train Epoch: 19 [21760/60000 (36%)]\tLoss: 0.001018\n",
      "Train Epoch: 19 [23040/60000 (38%)]\tLoss: 0.001074\n",
      "Train Epoch: 19 [24320/60000 (41%)]\tLoss: 0.001051\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.001047\n",
      "Train Epoch: 19 [26880/60000 (45%)]\tLoss: 0.001051\n",
      "Train Epoch: 19 [28160/60000 (47%)]\tLoss: 0.001047\n",
      "Train Epoch: 19 [29440/60000 (49%)]\tLoss: 0.000999\n",
      "Train Epoch: 19 [30720/60000 (51%)]\tLoss: 0.001000\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.001055\n",
      "Train Epoch: 19 [33280/60000 (55%)]\tLoss: 0.001045\n",
      "Train Epoch: 19 [34560/60000 (58%)]\tLoss: 0.001012\n",
      "Train Epoch: 19 [35840/60000 (60%)]\tLoss: 0.001039\n",
      "Train Epoch: 19 [37120/60000 (62%)]\tLoss: 0.001012\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.000991\n",
      "Train Epoch: 19 [39680/60000 (66%)]\tLoss: 0.001063\n",
      "Train Epoch: 19 [40960/60000 (68%)]\tLoss: 0.001015\n",
      "Train Epoch: 19 [42240/60000 (70%)]\tLoss: 0.001052\n",
      "Train Epoch: 19 [43520/60000 (72%)]\tLoss: 0.001025\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 0.001029\n",
      "Train Epoch: 19 [46080/60000 (77%)]\tLoss: 0.001046\n",
      "Train Epoch: 19 [47360/60000 (79%)]\tLoss: 0.001035\n",
      "Train Epoch: 19 [48640/60000 (81%)]\tLoss: 0.001064\n",
      "Train Epoch: 19 [49920/60000 (83%)]\tLoss: 0.001055\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.001013\n",
      "Train Epoch: 19 [52480/60000 (87%)]\tLoss: 0.001105\n",
      "Train Epoch: 19 [53760/60000 (90%)]\tLoss: 0.001030\n",
      "Train Epoch: 19 [55040/60000 (92%)]\tLoss: 0.001019\n",
      "Train Epoch: 19 [56320/60000 (94%)]\tLoss: 0.001058\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.001072\n",
      "Train Epoch: 19 [58880/60000 (98%)]\tLoss: 0.001003\n",
      "====> Epoch: 19 Average loss: 0.0010\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.001042\n",
      "Train Epoch: 20 [1280/60000 (2%)]\tLoss: 0.001010\n",
      "Train Epoch: 20 [2560/60000 (4%)]\tLoss: 0.000991\n",
      "Train Epoch: 20 [3840/60000 (6%)]\tLoss: 0.001011\n",
      "Train Epoch: 20 [5120/60000 (9%)]\tLoss: 0.001030\n",
      "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 0.001040\n",
      "Train Epoch: 20 [7680/60000 (13%)]\tLoss: 0.001030\n",
      "Train Epoch: 20 [8960/60000 (15%)]\tLoss: 0.001071\n",
      "Train Epoch: 20 [10240/60000 (17%)]\tLoss: 0.001024\n",
      "Train Epoch: 20 [11520/60000 (19%)]\tLoss: 0.001045\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.001027\n",
      "Train Epoch: 20 [14080/60000 (23%)]\tLoss: 0.001002\n",
      "Train Epoch: 20 [15360/60000 (26%)]\tLoss: 0.001039\n",
      "Train Epoch: 20 [16640/60000 (28%)]\tLoss: 0.001045\n",
      "Train Epoch: 20 [17920/60000 (30%)]\tLoss: 0.001041\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.001040\n",
      "Train Epoch: 20 [20480/60000 (34%)]\tLoss: 0.001040\n",
      "Train Epoch: 20 [21760/60000 (36%)]\tLoss: 0.001054\n",
      "Train Epoch: 20 [23040/60000 (38%)]\tLoss: 0.001042\n",
      "Train Epoch: 20 [24320/60000 (41%)]\tLoss: 0.001067\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.001016\n",
      "Train Epoch: 20 [26880/60000 (45%)]\tLoss: 0.001055\n",
      "Train Epoch: 20 [28160/60000 (47%)]\tLoss: 0.001052\n",
      "Train Epoch: 20 [29440/60000 (49%)]\tLoss: 0.001016\n",
      "Train Epoch: 20 [30720/60000 (51%)]\tLoss: 0.001082\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.001034\n",
      "Train Epoch: 20 [33280/60000 (55%)]\tLoss: 0.001074\n",
      "Train Epoch: 20 [34560/60000 (58%)]\tLoss: 0.001064\n",
      "Train Epoch: 20 [35840/60000 (60%)]\tLoss: 0.001039\n",
      "Train Epoch: 20 [37120/60000 (62%)]\tLoss: 0.001008\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.001034\n",
      "Train Epoch: 20 [39680/60000 (66%)]\tLoss: 0.001050\n",
      "Train Epoch: 20 [40960/60000 (68%)]\tLoss: 0.001036\n",
      "Train Epoch: 20 [42240/60000 (70%)]\tLoss: 0.001031\n",
      "Train Epoch: 20 [43520/60000 (72%)]\tLoss: 0.001035\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 0.001043\n",
      "Train Epoch: 20 [46080/60000 (77%)]\tLoss: 0.001032\n",
      "Train Epoch: 20 [47360/60000 (79%)]\tLoss: 0.001004\n",
      "Train Epoch: 20 [48640/60000 (81%)]\tLoss: 0.001041\n",
      "Train Epoch: 20 [49920/60000 (83%)]\tLoss: 0.001043\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.001032\n",
      "Train Epoch: 20 [52480/60000 (87%)]\tLoss: 0.001043\n",
      "Train Epoch: 20 [53760/60000 (90%)]\tLoss: 0.001057\n",
      "Train Epoch: 20 [55040/60000 (92%)]\tLoss: 0.001015\n",
      "Train Epoch: 20 [56320/60000 (94%)]\tLoss: 0.001034\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.001049\n",
      "Train Epoch: 20 [58880/60000 (98%)]\tLoss: 0.001063\n",
      "====> Epoch: 20 Average loss: 0.0010\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.001027\n",
      "Train Epoch: 21 [1280/60000 (2%)]\tLoss: 0.001020\n",
      "Train Epoch: 21 [2560/60000 (4%)]\tLoss: 0.001017\n",
      "Train Epoch: 21 [3840/60000 (6%)]\tLoss: 0.001006\n",
      "Train Epoch: 21 [5120/60000 (9%)]\tLoss: 0.001043\n",
      "Train Epoch: 21 [6400/60000 (11%)]\tLoss: 0.001044\n",
      "Train Epoch: 21 [7680/60000 (13%)]\tLoss: 0.001041\n",
      "Train Epoch: 21 [8960/60000 (15%)]\tLoss: 0.001021\n",
      "Train Epoch: 21 [10240/60000 (17%)]\tLoss: 0.001003\n",
      "Train Epoch: 21 [11520/60000 (19%)]\tLoss: 0.001039\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.001003\n",
      "Train Epoch: 21 [14080/60000 (23%)]\tLoss: 0.001045\n",
      "Train Epoch: 21 [15360/60000 (26%)]\tLoss: 0.001015\n",
      "Train Epoch: 21 [16640/60000 (28%)]\tLoss: 0.001025\n",
      "Train Epoch: 21 [17920/60000 (30%)]\tLoss: 0.001030\n",
      "Train Epoch: 21 [19200/60000 (32%)]\tLoss: 0.001022\n",
      "Train Epoch: 21 [20480/60000 (34%)]\tLoss: 0.001077\n",
      "Train Epoch: 21 [21760/60000 (36%)]\tLoss: 0.001059\n",
      "Train Epoch: 21 [23040/60000 (38%)]\tLoss: 0.001032\n",
      "Train Epoch: 21 [24320/60000 (41%)]\tLoss: 0.001037\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.001040\n",
      "Train Epoch: 21 [26880/60000 (45%)]\tLoss: 0.001017\n",
      "Train Epoch: 21 [28160/60000 (47%)]\tLoss: 0.001037\n",
      "Train Epoch: 21 [29440/60000 (49%)]\tLoss: 0.001042\n",
      "Train Epoch: 21 [30720/60000 (51%)]\tLoss: 0.001028\n",
      "Train Epoch: 21 [32000/60000 (53%)]\tLoss: 0.000999\n",
      "Train Epoch: 21 [33280/60000 (55%)]\tLoss: 0.000994\n",
      "Train Epoch: 21 [34560/60000 (58%)]\tLoss: 0.001004\n",
      "Train Epoch: 21 [35840/60000 (60%)]\tLoss: 0.001013\n",
      "Train Epoch: 21 [37120/60000 (62%)]\tLoss: 0.001009\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.001024\n",
      "Train Epoch: 21 [39680/60000 (66%)]\tLoss: 0.001015\n",
      "Train Epoch: 21 [40960/60000 (68%)]\tLoss: 0.001076\n",
      "Train Epoch: 21 [42240/60000 (70%)]\tLoss: 0.001024\n",
      "Train Epoch: 21 [43520/60000 (72%)]\tLoss: 0.001038\n",
      "Train Epoch: 21 [44800/60000 (75%)]\tLoss: 0.001084\n",
      "Train Epoch: 21 [46080/60000 (77%)]\tLoss: 0.001016\n",
      "Train Epoch: 21 [47360/60000 (79%)]\tLoss: 0.001042\n",
      "Train Epoch: 21 [48640/60000 (81%)]\tLoss: 0.001030\n",
      "Train Epoch: 21 [49920/60000 (83%)]\tLoss: 0.000999\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.001008\n",
      "Train Epoch: 21 [52480/60000 (87%)]\tLoss: 0.001026\n",
      "Train Epoch: 21 [53760/60000 (90%)]\tLoss: 0.001031\n",
      "Train Epoch: 21 [55040/60000 (92%)]\tLoss: 0.001075\n",
      "Train Epoch: 21 [56320/60000 (94%)]\tLoss: 0.001001\n",
      "Train Epoch: 21 [57600/60000 (96%)]\tLoss: 0.001026\n",
      "Train Epoch: 21 [58880/60000 (98%)]\tLoss: 0.001021\n",
      "====> Epoch: 21 Average loss: 0.0010\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.001026\n",
      "Train Epoch: 22 [1280/60000 (2%)]\tLoss: 0.001012\n",
      "Train Epoch: 22 [2560/60000 (4%)]\tLoss: 0.001024\n",
      "Train Epoch: 22 [3840/60000 (6%)]\tLoss: 0.001062\n",
      "Train Epoch: 22 [5120/60000 (9%)]\tLoss: 0.001008\n",
      "Train Epoch: 22 [6400/60000 (11%)]\tLoss: 0.001098\n",
      "Train Epoch: 22 [7680/60000 (13%)]\tLoss: 0.001060\n",
      "Train Epoch: 22 [8960/60000 (15%)]\tLoss: 0.001026\n",
      "Train Epoch: 22 [10240/60000 (17%)]\tLoss: 0.001038\n",
      "Train Epoch: 22 [11520/60000 (19%)]\tLoss: 0.001039\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.001028\n",
      "Train Epoch: 22 [14080/60000 (23%)]\tLoss: 0.001034\n",
      "Train Epoch: 22 [15360/60000 (26%)]\tLoss: 0.001055\n",
      "Train Epoch: 22 [16640/60000 (28%)]\tLoss: 0.001038\n",
      "Train Epoch: 22 [17920/60000 (30%)]\tLoss: 0.000996\n",
      "Train Epoch: 22 [19200/60000 (32%)]\tLoss: 0.001019\n",
      "Train Epoch: 22 [20480/60000 (34%)]\tLoss: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [21760/60000 (36%)]\tLoss: 0.001010\n",
      "Train Epoch: 22 [23040/60000 (38%)]\tLoss: 0.001015\n",
      "Train Epoch: 22 [24320/60000 (41%)]\tLoss: 0.001055\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.001053\n",
      "Train Epoch: 22 [26880/60000 (45%)]\tLoss: 0.000986\n",
      "Train Epoch: 22 [28160/60000 (47%)]\tLoss: 0.001030\n",
      "Train Epoch: 22 [29440/60000 (49%)]\tLoss: 0.001034\n",
      "Train Epoch: 22 [30720/60000 (51%)]\tLoss: 0.001038\n",
      "Train Epoch: 22 [32000/60000 (53%)]\tLoss: 0.001013\n",
      "Train Epoch: 22 [33280/60000 (55%)]\tLoss: 0.001038\n",
      "Train Epoch: 22 [34560/60000 (58%)]\tLoss: 0.001021\n",
      "Train Epoch: 22 [35840/60000 (60%)]\tLoss: 0.001011\n",
      "Train Epoch: 22 [37120/60000 (62%)]\tLoss: 0.001042\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.001030\n",
      "Train Epoch: 22 [39680/60000 (66%)]\tLoss: 0.001028\n",
      "Train Epoch: 22 [40960/60000 (68%)]\tLoss: 0.001051\n",
      "Train Epoch: 22 [42240/60000 (70%)]\tLoss: 0.001069\n",
      "Train Epoch: 22 [43520/60000 (72%)]\tLoss: 0.001049\n",
      "Train Epoch: 22 [44800/60000 (75%)]\tLoss: 0.001029\n",
      "Train Epoch: 22 [46080/60000 (77%)]\tLoss: 0.001008\n",
      "Train Epoch: 22 [47360/60000 (79%)]\tLoss: 0.001042\n",
      "Train Epoch: 22 [48640/60000 (81%)]\tLoss: 0.000992\n",
      "Train Epoch: 22 [49920/60000 (83%)]\tLoss: 0.001011\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.001032\n",
      "Train Epoch: 22 [52480/60000 (87%)]\tLoss: 0.001082\n",
      "Train Epoch: 22 [53760/60000 (90%)]\tLoss: 0.001015\n",
      "Train Epoch: 22 [55040/60000 (92%)]\tLoss: 0.001047\n",
      "Train Epoch: 22 [56320/60000 (94%)]\tLoss: 0.000985\n",
      "Train Epoch: 22 [57600/60000 (96%)]\tLoss: 0.001049\n",
      "Train Epoch: 22 [58880/60000 (98%)]\tLoss: 0.001009\n",
      "====> Epoch: 22 Average loss: 0.0010\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.001044\n",
      "Train Epoch: 23 [1280/60000 (2%)]\tLoss: 0.001063\n",
      "Train Epoch: 23 [2560/60000 (4%)]\tLoss: 0.001040\n",
      "Train Epoch: 23 [3840/60000 (6%)]\tLoss: 0.001043\n",
      "Train Epoch: 23 [5120/60000 (9%)]\tLoss: 0.001061\n",
      "Train Epoch: 23 [6400/60000 (11%)]\tLoss: 0.001043\n",
      "Train Epoch: 23 [7680/60000 (13%)]\tLoss: 0.001057\n",
      "Train Epoch: 23 [8960/60000 (15%)]\tLoss: 0.001055\n",
      "Train Epoch: 23 [10240/60000 (17%)]\tLoss: 0.001038\n",
      "Train Epoch: 23 [11520/60000 (19%)]\tLoss: 0.001035\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.001026\n",
      "Train Epoch: 23 [14080/60000 (23%)]\tLoss: 0.001061\n",
      "Train Epoch: 23 [15360/60000 (26%)]\tLoss: 0.001018\n",
      "Train Epoch: 23 [16640/60000 (28%)]\tLoss: 0.001031\n",
      "Train Epoch: 23 [17920/60000 (30%)]\tLoss: 0.001015\n",
      "Train Epoch: 23 [19200/60000 (32%)]\tLoss: 0.001063\n",
      "Train Epoch: 23 [20480/60000 (34%)]\tLoss: 0.000992\n",
      "Train Epoch: 23 [21760/60000 (36%)]\tLoss: 0.001041\n",
      "Train Epoch: 23 [23040/60000 (38%)]\tLoss: 0.001052\n",
      "Train Epoch: 23 [24320/60000 (41%)]\tLoss: 0.001073\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.001027\n",
      "Train Epoch: 23 [26880/60000 (45%)]\tLoss: 0.001011\n",
      "Train Epoch: 23 [28160/60000 (47%)]\tLoss: 0.000992\n",
      "Train Epoch: 23 [29440/60000 (49%)]\tLoss: 0.001057\n",
      "Train Epoch: 23 [30720/60000 (51%)]\tLoss: 0.001038\n",
      "Train Epoch: 23 [32000/60000 (53%)]\tLoss: 0.001037\n",
      "Train Epoch: 23 [33280/60000 (55%)]\tLoss: 0.001041\n",
      "Train Epoch: 23 [34560/60000 (58%)]\tLoss: 0.001064\n",
      "Train Epoch: 23 [35840/60000 (60%)]\tLoss: 0.001007\n",
      "Train Epoch: 23 [37120/60000 (62%)]\tLoss: 0.001061\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.001027\n",
      "Train Epoch: 23 [39680/60000 (66%)]\tLoss: 0.001033\n",
      "Train Epoch: 23 [40960/60000 (68%)]\tLoss: 0.001079\n",
      "Train Epoch: 23 [42240/60000 (70%)]\tLoss: 0.001026\n",
      "Train Epoch: 23 [43520/60000 (72%)]\tLoss: 0.001007\n",
      "Train Epoch: 23 [44800/60000 (75%)]\tLoss: 0.001002\n",
      "Train Epoch: 23 [46080/60000 (77%)]\tLoss: 0.001018\n",
      "Train Epoch: 23 [47360/60000 (79%)]\tLoss: 0.001038\n",
      "Train Epoch: 23 [48640/60000 (81%)]\tLoss: 0.001024\n",
      "Train Epoch: 23 [49920/60000 (83%)]\tLoss: 0.001059\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.001022\n",
      "Train Epoch: 23 [52480/60000 (87%)]\tLoss: 0.001017\n",
      "Train Epoch: 23 [53760/60000 (90%)]\tLoss: 0.000979\n",
      "Train Epoch: 23 [55040/60000 (92%)]\tLoss: 0.001004\n",
      "Train Epoch: 23 [56320/60000 (94%)]\tLoss: 0.000979\n",
      "Train Epoch: 23 [57600/60000 (96%)]\tLoss: 0.001010\n",
      "Train Epoch: 23 [58880/60000 (98%)]\tLoss: 0.001007\n",
      "====> Epoch: 23 Average loss: 0.0010\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.001034\n",
      "Train Epoch: 24 [1280/60000 (2%)]\tLoss: 0.001050\n",
      "Train Epoch: 24 [2560/60000 (4%)]\tLoss: 0.001020\n",
      "Train Epoch: 24 [3840/60000 (6%)]\tLoss: 0.001009\n",
      "Train Epoch: 24 [5120/60000 (9%)]\tLoss: 0.001055\n",
      "Train Epoch: 24 [6400/60000 (11%)]\tLoss: 0.001028\n",
      "Train Epoch: 24 [7680/60000 (13%)]\tLoss: 0.001030\n",
      "Train Epoch: 24 [8960/60000 (15%)]\tLoss: 0.001040\n",
      "Train Epoch: 24 [10240/60000 (17%)]\tLoss: 0.001065\n",
      "Train Epoch: 24 [11520/60000 (19%)]\tLoss: 0.001029\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.000997\n",
      "Train Epoch: 24 [14080/60000 (23%)]\tLoss: 0.001060\n",
      "Train Epoch: 24 [15360/60000 (26%)]\tLoss: 0.001035\n",
      "Train Epoch: 24 [16640/60000 (28%)]\tLoss: 0.000981\n",
      "Train Epoch: 24 [17920/60000 (30%)]\tLoss: 0.001060\n",
      "Train Epoch: 24 [19200/60000 (32%)]\tLoss: 0.000981\n",
      "Train Epoch: 24 [20480/60000 (34%)]\tLoss: 0.001059\n",
      "Train Epoch: 24 [21760/60000 (36%)]\tLoss: 0.001015\n",
      "Train Epoch: 24 [23040/60000 (38%)]\tLoss: 0.000998\n",
      "Train Epoch: 24 [24320/60000 (41%)]\tLoss: 0.001065\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.001038\n",
      "Train Epoch: 24 [26880/60000 (45%)]\tLoss: 0.001001\n",
      "Train Epoch: 24 [28160/60000 (47%)]\tLoss: 0.001014\n",
      "Train Epoch: 24 [29440/60000 (49%)]\tLoss: 0.001047\n",
      "Train Epoch: 24 [30720/60000 (51%)]\tLoss: 0.001057\n",
      "Train Epoch: 24 [32000/60000 (53%)]\tLoss: 0.001028\n",
      "Train Epoch: 24 [33280/60000 (55%)]\tLoss: 0.001051\n",
      "Train Epoch: 24 [34560/60000 (58%)]\tLoss: 0.001058\n",
      "Train Epoch: 24 [35840/60000 (60%)]\tLoss: 0.001033\n",
      "Train Epoch: 24 [37120/60000 (62%)]\tLoss: 0.001006\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.001026\n",
      "Train Epoch: 24 [39680/60000 (66%)]\tLoss: 0.001037\n",
      "Train Epoch: 24 [40960/60000 (68%)]\tLoss: 0.001042\n",
      "Train Epoch: 24 [42240/60000 (70%)]\tLoss: 0.001022\n",
      "Train Epoch: 24 [43520/60000 (72%)]\tLoss: 0.001041\n",
      "Train Epoch: 24 [44800/60000 (75%)]\tLoss: 0.001043\n",
      "Train Epoch: 24 [46080/60000 (77%)]\tLoss: 0.001088\n",
      "Train Epoch: 24 [47360/60000 (79%)]\tLoss: 0.001041\n",
      "Train Epoch: 24 [48640/60000 (81%)]\tLoss: 0.001034\n",
      "Train Epoch: 24 [49920/60000 (83%)]\tLoss: 0.001062\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.000972\n",
      "Train Epoch: 24 [52480/60000 (87%)]\tLoss: 0.001054\n",
      "Train Epoch: 24 [53760/60000 (90%)]\tLoss: 0.001035\n",
      "Train Epoch: 24 [55040/60000 (92%)]\tLoss: 0.001010\n",
      "Train Epoch: 24 [56320/60000 (94%)]\tLoss: 0.001023\n",
      "Train Epoch: 24 [57600/60000 (96%)]\tLoss: 0.001030\n",
      "Train Epoch: 24 [58880/60000 (98%)]\tLoss: 0.001050\n",
      "====> Epoch: 24 Average loss: 0.0010\n",
      "====> Test set loss: 0.0010\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.001025\n",
      "Train Epoch: 25 [1280/60000 (2%)]\tLoss: 0.001047\n",
      "Train Epoch: 25 [2560/60000 (4%)]\tLoss: 0.001015\n",
      "Train Epoch: 25 [3840/60000 (6%)]\tLoss: 0.001010\n",
      "Train Epoch: 25 [5120/60000 (9%)]\tLoss: 0.001029\n",
      "Train Epoch: 25 [6400/60000 (11%)]\tLoss: 0.000993\n",
      "Train Epoch: 25 [7680/60000 (13%)]\tLoss: 0.001014\n",
      "Train Epoch: 25 [8960/60000 (15%)]\tLoss: 0.001063\n",
      "Train Epoch: 25 [10240/60000 (17%)]\tLoss: 0.001030\n",
      "Train Epoch: 25 [11520/60000 (19%)]\tLoss: 0.001002\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.001042\n",
      "Train Epoch: 25 [14080/60000 (23%)]\tLoss: 0.001019\n",
      "Train Epoch: 25 [15360/60000 (26%)]\tLoss: 0.001050\n",
      "Train Epoch: 25 [16640/60000 (28%)]\tLoss: 0.001034\n",
      "Train Epoch: 25 [17920/60000 (30%)]\tLoss: 0.001029\n",
      "Train Epoch: 25 [19200/60000 (32%)]\tLoss: 0.001000\n",
      "Train Epoch: 25 [20480/60000 (34%)]\tLoss: 0.001038\n",
      "Train Epoch: 25 [21760/60000 (36%)]\tLoss: 0.001046\n",
      "Train Epoch: 25 [23040/60000 (38%)]\tLoss: 0.001063\n",
      "Train Epoch: 25 [24320/60000 (41%)]\tLoss: 0.001055\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.001027\n",
      "Train Epoch: 25 [26880/60000 (45%)]\tLoss: 0.001002\n",
      "Train Epoch: 25 [28160/60000 (47%)]\tLoss: 0.001041\n",
      "Train Epoch: 25 [29440/60000 (49%)]\tLoss: 0.000988\n",
      "Train Epoch: 25 [30720/60000 (51%)]\tLoss: 0.001007\n",
      "Train Epoch: 25 [32000/60000 (53%)]\tLoss: 0.001034\n",
      "Train Epoch: 25 [33280/60000 (55%)]\tLoss: 0.001050\n",
      "Train Epoch: 25 [34560/60000 (58%)]\tLoss: 0.001014\n",
      "Train Epoch: 25 [35840/60000 (60%)]\tLoss: 0.001030\n",
      "Train Epoch: 25 [37120/60000 (62%)]\tLoss: 0.001009\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.001033\n",
      "Train Epoch: 25 [39680/60000 (66%)]\tLoss: 0.001038\n",
      "Train Epoch: 25 [40960/60000 (68%)]\tLoss: 0.001039\n",
      "Train Epoch: 25 [42240/60000 (70%)]\tLoss: 0.001010\n",
      "Train Epoch: 25 [43520/60000 (72%)]\tLoss: 0.001062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 [44800/60000 (75%)]\tLoss: 0.001004\n",
      "Train Epoch: 25 [46080/60000 (77%)]\tLoss: 0.001019\n",
      "Train Epoch: 25 [47360/60000 (79%)]\tLoss: 0.001048\n",
      "Train Epoch: 25 [48640/60000 (81%)]\tLoss: 0.001000\n",
      "Train Epoch: 25 [49920/60000 (83%)]\tLoss: 0.001018\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.001020\n",
      "Train Epoch: 25 [52480/60000 (87%)]\tLoss: 0.001009\n",
      "Train Epoch: 25 [53760/60000 (90%)]\tLoss: 0.001044\n",
      "Train Epoch: 25 [55040/60000 (92%)]\tLoss: 0.001040\n",
      "Train Epoch: 25 [56320/60000 (94%)]\tLoss: 0.001039\n",
      "Train Epoch: 25 [57600/60000 (96%)]\tLoss: 0.001025\n",
      "Train Epoch: 25 [58880/60000 (98%)]\tLoss: 0.001030\n",
      "====> Epoch: 25 Average loss: 0.0010\n",
      "====> Test set loss: 0.0010\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "\n",
    "    # 64 sets of random ZDIMS-float vectors, i.e. 64 locations / MNIST\n",
    "    # digits in latent space\n",
    "    sample = Variable(torch.randn(64, ZDIMS))\n",
    "    if CUDA:\n",
    "        sample = sample.cuda()\n",
    "    sample = model.decode(sample).cpu()\n",
    "\n",
    "    # save out as an 8x8 matrix of MNIST digits\n",
    "    # this will give you a visual idea of how well latent space can generate things\n",
    "    # that look like digits\n",
    "    save_image(sample.data.view(64, 1, 28, 28),\n",
    "               './results/sample_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T20:29:57.360580Z",
     "start_time": "2019-01-04T20:29:57.216925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "tensor([-0.3828, -0.0196, -1.5145,  0.6859, -1.1610, -0.0933, -1.8728,  1.0094,\n",
      "        -0.0874,  0.9154,  0.1435,  0.6889,  0.2936, -0.3767,  0.5583,  0.3631,\n",
      "        -2.3465,  0.9183, -0.9993,  0.3625], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff0e1f54f98>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = Variable(torch.randn(1, ZDIMS))\n",
    "\n",
    "if CUDA:\n",
    "    sample = sample.cuda()\n",
    "\n",
    "print(sample.shape)\n",
    "print(sample[0])\n",
    "\n",
    "sample = model.decode(sample).cpu()\n",
    "\n",
    "img_data = sample.data.view(1, 28, 28).numpy()\n",
    "\n",
    "\n",
    "plt.imshow(img_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate additional dataset based on the current MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T20:32:29.488565Z",
     "start_time": "2019-01-04T20:32:27.424675Z"
    }
   },
   "outputs": [],
   "source": [
    "additional_dataset = []\n",
    "\n",
    "for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "    data = Variable(data)\n",
    "    if CUDA:\n",
    "        data = data.cuda()\n",
    "    x = data.view(-1, 784)\n",
    "\n",
    "    out = model.transform(x)\n",
    "    out = out.view(-1, 1, 28, 28)\n",
    "    \n",
    "    \n",
    "    new_batch = [out, labels]\n",
    "\n",
    "    additional_dataset.append(new_batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T20:32:44.190784Z",
     "start_time": "2019-01-04T20:32:44.188117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n"
     ]
    }
   ],
   "source": [
    "print(len(additional_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
